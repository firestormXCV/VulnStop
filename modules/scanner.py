import time
import json
import os
import requests
from zapv2 import ZAPv2
from datetime import datetime
from modules.utils import get_clean_filename_from_url
from dotenv import load_dotenv

load_dotenv() # This pulls the variables from your .env file into os.environ

ZAP_API_KEY = os.getenv("ZAP_API_KEY")
#ZAP_PROXY_URL = os.getenv("ZAP_PROXY") # This is "http://localhost:8080"
ZAP_PROXY_URL = os.getenv("ZAP_PROXY")
# ZAPv2 expects a dictionary for the proxies parameter
proxies = {
    'http': ZAP_PROXY_URL,
    'https': ZAP_PROXY_URL
}

# R√©cup√©ration des variables d'env ici ou via config
ZAP_API_KEY = os.getenv("ZAP_API_KEY")
ZAP_PORT = '8080'
zap_url_env = os.getenv("ZAP_PROXY")

ZAP_PROXY = {
    "http": zap_url_env,
    "https": zap_url_env
}

def clean_alert_data(alert):
    """Fonction helper pour nettoyer une alerte brute ZAP et extraire les liens"""
    
    # 1. Extraction des liens depuis les TAGS
    tags = alert.get("tags", {})
    extracted_links = []
    
    # On parcourt les tags (ex: "OWASP_2021_A01": "https://...")
    for key, value in tags.items():
        if isinstance(value, str) and value.startswith("http"):
            extracted_links.append(value)
            
    # 2. Extraction depuis le champ REFERENCE (souvent pr√©sent aussi)
    refs = alert.get("reference", "")
    if refs.startswith("http") and refs not in extracted_links:
        extracted_links.append(refs)

    return {
        "title": alert.get("alert", "Inconnu"),
        "risk": alert.get("risk", "Inconnu"),
        "description": alert.get("description", "")[:500],
        "solution": alert.get("solution", ""),
        "urls": [], # Sera rempli par la boucle principale
        "reference_links": extracted_links # Liens utiles extraits
    }
# --- FONCTION PRINCIPALE ---
def run_zap_scan(target_url, max_threads, active_scan, progress_callback=None):
    if "#" in target_url:
        print(f"‚ö†Ô∏è URL avec fragment (#) d√©tect√©e. Nettoyage : {target_url} -> {target_url.split('#')[0]}")
        target_url = target_url.split("#")[0]
    
    # On retire le slash final pour √©viter les probl√®mes de matching strict
    target_url = target_url.rstrip('/')
    
    RISK_WEIGHT = {"High": 0, "Medium": 1, "Low": 2, "Informational": 3}
    print(f"üîå Tentative de connexion √† ZAP sur le port {ZAP_PORT}...")
    zap = ZAPv2(apikey=ZAP_API_KEY, proxies=ZAP_PROXY)    
    # 1. V√©rification connexion
    
    try:
        zap.core.version
        print("‚úÖ Connect√© √† ZAP !")
        print(f"Connected to ZAP version: {zap.core.version}")
    except Exception as e:
        print(f"Failed to connect to ZAP. Check if ZAP is running on {ZAP_PROXY_URL}")
        print(f"Error: {e}")
        error_msg = f"ERREUR CRITIQUE: ZAP n'est pas accessible sur {ZAP_PORT}. Lancez ZAP d'abord."
        print(error_msg,e)
        return json.dumps({"error": error_msg})

    # R√©initialisation
    zap.core.new_session(name=f"Session_{int(time.time())}", overwrite=True)
    
    # --- CONFIGURATION DYNAMIQUE ---

    zap.ascan.set_option_thread_per_host(max_threads)
    zap.spider.set_option_thread_count(max_threads)
    
    # Si tr√®s lent, on augmente le timeout r√©seau de ZAP
    if max_threads <= 3:
        zap.core.set_option_timeout_in_secs(20)
    # On d√©finit une regex pour exclure les fichiers statiques lourds
    regex_exclusion = ".*\\.(gif|jpg|jpeg|png|ico|css|woff|woff2)$"
    zap.spider.exclude_from_scan(regex_exclusion)
    zap.ascan.exclude_from_scan(regex_exclusion)
    # --- 1. SPIDER ---
    print(f"üï∑Ô∏è Spider sur {target_url}...")
    scan_id = zap.spider.scan(target_url)
    while int(zap.spider.status(scan_id)) < 100:
        if progress_callback:
            if not progress_callback(int(zap.spider.status(scan_id)), "üï∑Ô∏è Exploration (Spider)"):
                zap.spider.stop(scan_id); return json.dumps({"error": "Stop user"})
        time.sleep(1)
    
    # --- 2. ACTIVE SCAN ---
    if active_scan:
        print(f"‚ö° Active Scan (R√©cursif)...")
        scan_id = zap.ascan.scan(target_url, recurse=True)
        time.sleep(2)
        
        consecutive_errors = 0
        max_retries = 10 # On autorise 10 √©checs de connexion avant d'abandonner

        while True:
            try:
                # TENTATIVE DE CONNEXION
                status = zap.ascan.status(scan_id)
                
                # Si on arrive ici, la connexion a r√©ussi : on reset le compteur d'erreurs
                consecutive_errors = 0
                
                # PROTECTION ANTI-CRASH (Donn√©es invalides renvoy√©es par ZAP)
                if not str(status).isdigit():
                    if status == "does_not_exist":
                        print("‚úÖ Active Scan termin√© (ID plus actif).")
                    else:
                        print(f"‚ö†Ô∏è Statut Active Scan inconnu : {status}")
                    break
                    
                # Si c'est un nombre, on continue normalement
                status_int = int(status)
                
                if progress_callback:
                    if not progress_callback(status_int, "‚ö° Attaque (Active Scan)"):
                        zap.ascan.stop(scan_id)
                        return json.dumps({"error": "Scan stopp√© par l'utilisateur."})
                
                if status_int >= 100:
                    break
                
                # Pause normale entre deux v√©rifications
                time.sleep(2)

            # GESTION DES ERREURS DE CONNEXION (WinError 10048 / ProxyError)
            except (requests.exceptions.ProxyError, requests.exceptions.ConnectionError) as e:
                consecutive_errors += 1
                print(f"‚ö†Ô∏è ZAP ne r√©pond pas (Tentative {consecutive_errors}/{max_retries}). Le r√©seau est satur√©.")
                
                # PAUSE D'URGENCE : On attend 5 secondes pour laisser Windows lib√©rer les sockets
                time.sleep(5)
                
                if consecutive_errors >= max_retries:
                    print("‚ùå ERREUR CRITIQUE : ZAP est injoignable apr√®s plusieurs tentatives.")
                    break
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur inattendue dans la boucle Active Scan : {e}")
                break
    else:
        print("‚ÑπÔ∏è Active Scan SKIPP√â (Mode Passif).")

    # --- 3. R√âCUP√âRATION DES ALERTES (AVEC RETRIES) ---
    print("üìù R√©cup√©ration des alertes...")
    
    all_alerts_raw = []
    start_index = 0
    batch_size = 5000  # On r√©cup√®re 5000 alertes par appel (taille raisonnable)
    
    # Optimisation cruciale : On demande √† ZAP de filtrer l'URL lui-m√™me !
    # Cela √©vite de r√©cup√©rer les alertes d'autres sites polluants.
    target_base = target_url.rstrip('/')
    
    while True:
        try:
            # Appel API avec pagination (start/count) et filtre (baseurl)
            # baseurl : ZAP ne renvoie que les alertes concernant cette cible
            batch = zap.core.alerts(
                baseurl=target_url, 
                start=start_index, 
                count=batch_size
            )
            
            # Gestion des formats bizarres (au cas o√π ZAP renvoie une string ou un dict vide)
            if not batch:
                break # Fin des donn√©es
                
            if isinstance(batch, str):
                # Parfois ZAP renvoie une string vide "" au lieu d'une liste
                break
                
            if isinstance(batch, dict) and "alerts" in batch:
                batch = batch["alerts"]
                
            if not isinstance(batch, list):
                print(f"‚ö†Ô∏è Format de lot inattendu (Type: {type(batch)}). Arr√™t.")
                break
                
            # Si le lot est vide, on a fini
            if len(batch) == 0:
                break
                
            # Ajout au total
            all_alerts_raw.extend(batch)
            print(f"   üì• Re√ßu lot de {len(batch)} alertes (Total: {len(all_alerts_raw)})...")
            
            # On avance l'index pour le prochain tour
            start_index += batch_size
            
            # Si on a re√ßu moins que demand√©, c'est que c'√©tait le dernier lot
            if len(batch) < batch_size:
                break
                
        except Exception as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration du lot {start_index}: {e}")
            # En cas d'erreur r√©seau, on peut choisir d'arr√™ter ou de r√©essayer
            # Ici on arr√™te pour √©viter une boucle infinie d'erreurs
            break

    # --- NETTOYAGE FINAL ---
    # Le filtrage 'startswith' est th√©oriquement inutile gr√¢ce √† l'argument baseurl,
    # mais on le garde en double s√©curit√© (ceinture et bretelles).
    raw_alerts = []
    
    for alert in all_alerts_raw:
        if isinstance(alert, dict):
            # Parfois l'URL dans l'alerte diff√®re l√©g√®rement du baseurl demand√©
            if alert.get('url', '').startswith(target_base):
                raw_alerts.append(alert)
    
    # Si le filtre baseurl de ZAP a bien march√©, raw_alerts == all_alerts_raw
    # Sinon, on garde juste celles valid√©es.
    if not raw_alerts:
        raw_alerts = all_alerts_raw 

    print(f"‚úÖ R√©cup√©ration termin√©e : {len(raw_alerts)} alertes uniques r√©cup√©r√©es.")
    # ... (Suite : Sauvegarde...)

    # --- 4. SAUVEGARDE DU JSON BRUT ( ---
   
    # 1. On g√©n√®re un nom propre bas√© sur la racine (ex: demo_owasp_juice_shop)
    safe_root_name = get_clean_filename_from_url(target_url)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
  
    # --- 5. REGROUPEMENT POUR L'IA ---
    grouped_alerts = {}
    for alert in raw_alerts:
        title = alert.get("alert")
        risk = alert.get("risk")
        url = alert.get("url")
        key = f"{title}|{risk}"
        
        if key not in grouped_alerts:
            cleaned = clean_alert_data(alert)
            cleaned["urls"] = [url]
            cleaned["method"] = alert.get("method", "")
            cleaned["param"] = alert.get("param", "")
            grouped_alerts[key] = cleaned
        else:
            if url not in grouped_alerts[key]["urls"]:
                grouped_alerts[key]["urls"].append(url)

    # --- 6. FILTRAGE FINAL ---
    final_vulnerabilities_list = []
    
    # LISTE DES RISQUES ACCEPT√âS (Anglais + Fran√ßais)
    VALID_RISKS = ["High", "Medium", "Low", "Informational", "Elev√©e", "Moyenne", "Faible", "Informative"]

    for key, data in grouped_alerts.items():
        # On v√©rifie si le risque est dans notre liste autoris√©e
        if data["risk"] not in VALID_RISKS: 
             continue 
            
        data["urls"] = sorted(data["urls"])[:15] 
        final_vulnerabilities_list.append(data)

    final_vulnerabilities_list.sort(key=lambda x: RISK_WEIGHT.get(x['risk'], 4))

    # --- 7. SORTIE JSON TRAIT√â ---
    final_output = {
        "scan_summary": {
            "target_url": target_url,
            "timestamp": timestamp,
            "total_alerts_found": len(raw_alerts),
            "unique_vulnerabilities": len(final_vulnerabilities_list),
            
        },
        "vulnerabilities": final_vulnerabilities_list
    }
    
    # On r√©utilise le m√™me nom propre safe_root_name
    full_filename = f"zap_FULL_{safe_root_name}_{timestamp}.json"
    full_path = os.path.join("reports", full_filename)
    
    try:
        with open(full_path, "w", encoding="utf-8") as f:
            json.dump(final_output, f, indent=4, ensure_ascii=False)
        print(f"üíæ Rapport FINAL sauvegard√© : {full_path}")
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde FINAL : {e}")

    return json.dumps(final_output, indent=2)
